# Text Preprocessing for NLP

## Overview

This project focuses on essential text preprocessing techniques used in Natural Language Processing (NLP). The main objectives include:

- **Tokenization**: Splitting text into individual words or tokens.
- **Lemmatization**: Reducing words to their base or root form.
- **Stemming**: Cutting off derivational affixes to get the word's base form.
- **Cleaning**: Removing punctuation, numbers, and extra whitespace.

These preprocessing steps are critical for preparing raw text data for further analysis or modeling.

## Features

- **Tokenization**: Convert text into tokens (words).
- **Lemmatization**: Reduce words to their base or root form using the NLTK library.
- **Stemming**: Reduce words to their base form using the NLTK library.
- **Text Cleaning**: Remove punctuation, numbers, and excess whitespace.

## Files

- **`text_preprocessing_nlp.py`**: Python script that implements the text preprocessing steps.
- **`paragraphs.txt`**: Containing sample text file used for preprocessing.

## Usage

To run the preprocessing script:

1. **Clone the repository**:
    ```bash
    git clone https://github.com/yourusername/your-repo-name.git
    ```

2. **Navigate to the project directory**:
    ```bash
    cd your-repo-name
    ```

3. **Run the preprocessing script**:
    ```bash
    python preprocessing_script.py
    ```
